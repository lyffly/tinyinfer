# Copyright (C) 2024, Qwen Team, Alibaba Group.
# This file is distributed under the same license as the Qwen package.
#

msgid ""
msgstr ""
"Project-Id-Version: Qwen \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-06-06 19:37+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.15.0\n"

#: ../../source/web_ui/text_generation_webui.rst:2
#: 7f06bcde5ebb4647ae574fc8a19efe29
msgid "Text Generation Web UI"
msgstr "Text Generation Web UI"

#: ../../source/web_ui/text_generation_webui.rst:4
#: 0e6ad6ad47f248ed925f79788e6974df
msgid ""
"`Text Generation Web UI <https://github.com/oobabooga/text-generation-"
"webui>`__ (TGW, or usually referred to “oobabooga”) is a popular web UI "
"for text generation, similar to `AUTOMATIC1111/stable-diffusion-webui "
"<https://github.com/AUTOMATIC1111/stable-diffusion-webui>`__. It has "
"multiple interfaces, and supports multiple model backends, including "
"`Transformers <https://github.com/huggingface/transformers>`__, "
"`llama.cpp <https://github.com/ggerganov/llama.cpp>`__ (through `llama-"
"cpp-python <https://github.com/abetlen/llama-cpp-python>`__), `ExLlamaV2 "
"<https://github.com/turboderp/exllamav2>`__, `AutoGPTQ "
"<https://github.com/PanQiWei/AutoGPTQ>`__, `AutoAWQ <https://github.com"
"/casper-hansen/AutoAWQ>`__, `GPTQ-for-LLaMa "
"<https://github.com/qwopqwop200/GPTQ-for-LLaMa>`__, `CTransformers "
"<https://github.com/marella/ctransformers>`__, `QuIP# <https://github.com"
"/Cornell-RelaxML/quip-sharp>`__. In this section, we introduce how to run"
" Qwen locally with TGW."
msgstr ""
"`Text Generation Web UI <https://github.com/oobabooga/text-generation-"
"webui>`__ （简称TGW，通常被称为“oobabooga”）是一款流行的文本生成Web界面工具，类似于 `AUTOMATIC1111"
"/stable-diffusion-webui <https://github.com/AUTOMATIC1111/stable-"
"diffusion-webui>`__ 。它拥有多个交互界面，并支持多种模型后端，包括 `Transformers "
"<https://github.com/huggingface/transformers>`__ 、 `llama.cpp "
"<https://github.com/ggerganov/llama.cpp>`__ （通过 `llama-cpp-python "
"<https://github.com/abetlen/llama-cpp-python>`__ 实现）、 `ExLlamaV2 "
"<https://github.com/turboderp/exllamav2>`__ 、 `AutoGPTQ "
"<https://github.com/PanQiWei/AutoGPTQ>`__ 、 `AutoAWQ <https://github.com"
"/casper-hansen/AutoAWQ>`__ 、 `GPTQ-for-LLaMa "
"<https://github.com/qwopqwop200/GPTQ-for-LLaMa>`__ 、 `CTransformers "
"<https://github.com/marella/ctransformers>`__ 以及 `QuIP# "
"<https://github.com/Cornell-RelaxML/quip-sharp>`__ "
"。在本节中，我们将介绍如何在本地环境中使用TGW运行Qwen。"

#: ../../source/web_ui/text_generation_webui.rst:23
#: db17fc39e0c248ff9ae7c406a543e28f
msgid "Quickstart"
msgstr "快速开始"

#: ../../source/web_ui/text_generation_webui.rst:25
#: e35b382744114e69b2d7e0b7d8bdfba9
msgid ""
"The simplest way to run TGW is to use the provided shell scripts in the "
"`repo <https://github.com/oobabooga/text-generation-webui>`__. For the "
"first step, clone the repo and enter the directory:"
msgstr ""
"最简单的运行TGW（Text Generation WebUI）的方法是使用 `repo "
"<https://github.com/oobabooga/text-generation-webui>`__ "
"中提供的Shell脚本。首先，克隆repo并进去文件夹中："

#: ../../source/web_ui/text_generation_webui.rst:34
#: fa53a5c0a71246f1ac7e6cb6fe686eb3
msgid ""
"You can directly run the ``start_linux.sh``, ``start_windows.bat``, "
"``start_macos.sh``, or ``start_wsl.bat`` script depending on your OS. "
"Alternatively you can manually install the requirements in your conda "
"environment. Here I take the practice on MacOS as an example."
msgstr ""
"你可以根据你的操作系统直接运行相应的脚本，例如在Linux系统上运行 ``start_linux.sh`` ，在Windows系统上运行 "
"``start_windows.bat`` ，在MacOS系统上运行 ``start_macos.sh`` "
"，或者在Windows子系统Linux（WSL）上运行 ``start_wsl.bat`` "
"。另外，你也可以选择手动在conda环境中安装所需的依赖项。这里以MacOS系统为例进行实践操作。"

#: ../../source/web_ui/text_generation_webui.rst:45
#: 95e2832b840a4ba98957e1c007653982
msgid ""
"Then you can install the requirements by running ``pip install -r`` based"
" on your OS, e.g.,"
msgstr "接下来，您可以根据您的操作系统执行 ``pip install -r`` 命令来安装相应的依赖项，例如，"

#: ../../source/web_ui/text_generation_webui.rst:52
#: dd126288544f4693ac83415914af8568

msgid ""
"For ``bitsandbytes`` and ``llama-cpp-python`` inside the requirements, I "
"advise you to install them through ``pip`` directly. However, temporarily"
" please do not use GGUF as the performance with TGW is unsatisfactory. "
"After finishing the installation of required packages, you need to "
"prepare your models by putting the model files or directories in the "
"folder ``./models``. For example, you should put the transformers model "
"directory of ``Qwen2-7B-Instruct`` in the way shown below:"
msgstr ""
"对于requirements中的 ``bitsandbytes`` 和 ``llama-cpp-python`` ，我建议您直接通过 "
"``pip`` "
"进行安装。但是，暂时请不要使用GGUF，因为其与TGW配合时的性能表现不佳。在完成所需包的安装之后，您需要准备模型，将模型文件或目录放在 ``./models`` 文件夹中。"
"例如，您应按照以下方式将 ``Qwen2-7B-Instruct`` 的transformers模型目录放置到相应位置。" 

#: ../../source/web_ui/text_generation_webui.rst:76
#: 9860e39a2b264e2e924b60bf7a09691e
msgid "Then you just need to run"
msgstr "随后你需要运行"

#: ../../source/web_ui/text_generation_webui.rst:82
#: 42110f758571443da37a6736bd099142
msgid "to launch your web UI service. Please browse to"
msgstr "来启动你的网页服务。请点击进入"

#: ../../source/web_ui/text_generation_webui.rst:88
#: 5f703627ce5b41e7aeb4f4243c97a4f9
msgid "and enjoy playing with Qwen in a web UI!"
msgstr "然后享受使用Qwen的Web UI吧！"

#: ../../source/web_ui/text_generation_webui.rst:91
#: 3975364cff5a45f8b8127c76ff15a44d
msgid "Next Step"
msgstr "下一步"

#: ../../source/web_ui/text_generation_webui.rst:93
#: 3d839a1474744399887df47cc70adc82
msgid ""
"There are a lot more usages in TGW, where you can even enjoy role play, "
"use different types of quantized models, train LoRA, incorporate "
"extensions like stable diffusion and whisper, etc. Go to figure out more "
"advanced usages and apply them to Qwen models!"
msgstr ""
"TGW 中包含了许多更多用途，您甚至可以在其中享受角色扮演的乐趣，并使用不同类型的量化模型。您可以训练诸如LoRA这样的算法，并将Stable "
"Diffusion和Whisper等扩展功能纳入其中。赶快去探索更多高级用法，并将它们应用于Qwen模型中吧！"

